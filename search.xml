<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>机器学习笔记2</title>
    <url>/2020/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</url>
    <content><![CDATA[<h3 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h3><h4 id="一：机器学习的数据"><a href="#一：机器学习的数据" class="headerlink" title="一：机器学习的数据"></a>一：机器学习的数据</h4><a id="more"></a>
<h5 id="1-以鸢尾花数据来举例"><a href="#1-以鸢尾花数据来举例" class="headerlink" title="1.以鸢尾花数据来举例"></a>1.以鸢尾花数据来举例</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706180226511.png" alt="image-20200706180226511"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706180341873_1.png" alt="image-20200706180341873_1"></p>
<ul>
<li>注意：种类是用0,1,2来表示的。</li>
</ul>
<h5 id="2-从该数据集中引出的基本概念"><a href="#2-从该数据集中引出的基本概念" class="headerlink" title="2.从该数据集中引出的基本概念"></a>2.从该数据集中引出的基本概念</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706181305828.png" alt="image-20200706181305828"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706221107817_1.png" alt="image-20200706221107817_1"></p>
<p>注意:</p>
<ul>
<li>在机器学习中，大写字母表示矩阵，小写字母表示向量</li>
<li>标记y是机器学习真正要学习（预测）的</li>
<li>一般来说，特征向量都是列向量，所以如果表示整个特征集，需要将每个特征向量转置为行向量（看上图理解）</li>
</ul>
<p>#####3.为了可视化方便，取鸢尾花的前两个特征（长度，宽度）绘图</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706221859929.png" alt="image-20200706221859929"></p>
<p>解释：</p>
<ul>
<li>红蓝代表两种鸢尾花，一个点落入哪块儿区域就说明是哪种类型的鸢尾花。</li>
<li>玩具数据集的特征空间切分可能是直线，但是现实中的数据集一般不可能用直线正好切分</li>
<li>有时若在高维空间不好理解，可以类比为低维度空间理解，然后再迁移到高维空间 </li>
</ul>
<h5 id="4-特征不一定是具有语义的，比如下图（像素点指每一个小矩形）"><a href="#4-特征不一定是具有语义的，比如下图（像素点指每一个小矩形）" class="headerlink" title="4.特征不一定是具有语义的，比如下图（像素点指每一个小矩形）"></a>4.特征不一定是具有语义的，比如下图（像素点指每一个小矩形）</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706223051356.png" alt="image-20200706223051356"></p>
<h4 id="二：机器学习（监督学习）的基本任务"><a href="#二：机器学习（监督学习）的基本任务" class="headerlink" title="二：机器学习（监督学习）的基本任务"></a>二：机器学习（监督学习）的基本任务</h4><h5 id="1-机器学习（监督学习）的基本任务主要分为：分类和回归"><a href="#1-机器学习（监督学习）的基本任务主要分为：分类和回归" class="headerlink" title="1.机器学习（监督学习）的基本任务主要分为：分类和回归"></a>1.机器学习（监督学习）的基本任务主要分为：分类和回归</h5><h5 id="2-分类任务："><a href="#2-分类任务：" class="headerlink" title="2.分类任务："></a>2.分类任务：</h5><ul>
<li><p>二分类：如垃圾邮件判断</p>
</li>
<li><p>多分类：</p>
<ul>
<li>如数字识别，图像识别</li>
<li>其实很多复杂问题可以转换为多分类问题，比如下围棋，无人驾驶</li>
<li>一些算法只支持二分类，但可以转换为多分类</li>
<li>但是多分类可以转换为二分类</li>
<li>有一些算法天然支持多分类任务</li>
</ul>
</li>
<li><p>多标签分类：属于cv方向</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706224809022.png" alt="image-20200706224809022"></p>
</li>
</ul>
<h5 id="3-回归任务：结果是一个连续值，而不是一个类别"><a href="#3-回归任务：结果是一个连续值，而不是一个类别" class="headerlink" title="3.回归任务：结果是一个连续值，而不是一个类别"></a>3.回归任务：结果是一个连续值，而不是一个类别</h5><ul>
<li>如房屋价格，市场分析，学生成绩，股票价格</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706225329441.png" alt="image-20200706225329441"></p>
<ul>
<li>一些情况下，回归任务可以转换为分类任务<ul>
<li>如要预测学生成绩，可以预测具体成绩（回归），也可以预测成绩评级（分类）</li>
</ul>
</li>
</ul>
<h4 id="三：机器学习的分类"><a href="#三：机器学习的分类" class="headerlink" title="三：机器学习的分类"></a>三：机器学习的分类</h4><ul>
<li><p>监督学习：给机器的训练数据有标签（y）</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706230605230.png" alt="image-20200706230605230"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706230631948.png" alt="image-20200706230631948"></p>
</li>
<li><p>非监督学习：给机器的训练数据没有任何标签</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706230857321.png" alt="image-20200706230857321"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706231214211.png" alt="image-20200706231214211"></p>
<ul>
<li>特征压缩指在尽量小的损失下，将高维度数据转换为低维度数据</li>
<li>降维处理的意义：方便可视化，因为人类无法理解四维以上的空间</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706231654647.png" alt="image-20200706231654647"></p>
</li>
<li><p>半监督学习：一部分数据有标签，另一部分数据没有，更符合现实情况</p>
<ul>
<li>通常都是先使用无监督学习手段对数据做处理，之后用监督学习手段做模型的训练与预测</li>
</ul>
</li>
<li><p>强化学习</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706233156709_1.png" alt="image-20200706233156709_1"></p>
<ul>
<li>Agent（指算法）会根据环境（environment）来做出一些行为（action），然后Agent会收到一些反馈，有时是奖赏（reward），有时是惩罚。根据这些反馈Agent会改进自己的行为（action）模式，在一轮轮迭代中逐渐增强自己的智能</li>
</ul>
</li>
</ul>
<h4 id="四：机器学习的其他分类"><a href="#四：机器学习的其他分类" class="headerlink" title="四：机器学习的其他分类"></a>四：机器学习的其他分类</h4><ul>
<li><p>批量学习（离线学习）（Batch learning）</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706234715003_1.png" alt="image-20200706234715003_1"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706234926469.png" alt="image-20200706234926469"></p>
<ul>
<li>如股票预测，因为其每时每刻都在变化</li>
<li>而垃圾邮件分类就可以定时重新批量学习，因为变化频率低 </li>
</ul>
</li>
<li><p>在线学习（Online Learning）</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707011631601.png" alt="image-20200707011631601"></p>
<ul>
<li>输入样例输入模型以后会输出预测值，同时输入样例里的真实值也会输出 ，最终真实值，预测值，它们之间的差异等构成新的学习资料传给算法进行算法修正。</li>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707012338369.png" alt="image-20200707012338369"></li>
</ul>
</li>
<li><p>批量学习（离线学习）</p>
</li>
<li><p>参数学习（parametric learning）</p>
<ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707012614143.png" alt="image-20200707012614143"><ul>
<li>我们假设该模型的的函数是线性回归，然后想办法找到最优的a和b这两个参数</li>
<li>一旦学到了参数，就不再需要原有的数据集</li>
</ul>
</li>
</ul>
</li>
<li><p>非参数学习（nonparametric learning）</p>
<ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707013028462.png" alt="image-20200707013028462"></li>
<li>详细可参考<a href="https://www.cnblogs.com/wjunneng/p/9126906.html" target="_blank" rel="noopener">https://www.cnblogs.com/wjunneng/p/9126906.html</a></li>
</ul>
</li>
</ul>
<h4 id="五：和机器学习相关的哲学思考"><a href="#五：和机器学习相关的哲学思考" class="headerlink" title="五：和机器学习相关的哲学思考"></a>五：和机器学习相关的哲学思考</h4><h5 id="1-问题引出："><a href="#1-问题引出：" class="headerlink" title="1.问题引出："></a>1.问题引出：</h5><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707013704925_1.png" alt="image-20200707013704925_1"></p>
</li>
<li><ul>
<li>纵坐标表示算法准确度，横坐标表示数据规模（数据量），可以看到随着数据量的增大，4种算法的准确度都处于上升状态，最终的差距越来越小</li>
</ul>
</li>
</ul>
<h5 id="2-争论点："><a href="#2-争论点：" class="headerlink" title="2.争论点："></a>2.争论点：</h5><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707014212423.png" alt="image-20200707014212423"></p>
</li>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707014340413.png" alt="image-20200707014340413"></p>
</li>
</ul>
<h5 id="3-总结："><a href="#3-总结：" class="headerlink" title="3.总结："></a>3.总结：</h5><ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707014718816_1.png" alt="image-20200707014718816_1"></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>机器学习基础概念</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记1</title>
    <url>/2020/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/</url>
    <content><![CDATA[<h1 id="机器学习笔记"><a href="#机器学习笔记" class="headerlink" title="机器学习笔记"></a>机器学习笔记</h1><a id="more"></a>
<h3 id="一：什么是机器学习"><a href="#一：什么是机器学习" class="headerlink" title="一：什么是机器学习"></a>一：什么是机器学习</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706165617797.png" alt="image-20200706165617797"></p>
<h4 id="首先先了解人类如何学习（经验学习）"><a href="#首先先了解人类如何学习（经验学习）" class="headerlink" title="首先先了解人类如何学习（经验学习）"></a>首先先了解人类如何学习（经验学习）</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706170401290.png" alt="image-20200706170401290"></p>
<p>####机器学习和人类学习是非常相似的</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706170712331.png" alt="image-20200706170712331"></p>
<h3 id="二：机器学习应用"><a href="#二：机器学习应用" class="headerlink" title="二：机器学习应用"></a>二：机器学习应用</h3><h4 id="1-当前应用"><a href="#1-当前应用" class="headerlink" title="1.当前应用"></a>1.当前应用</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706171220946.png" alt="image-20200706171220946"></p>
<h4 id="2-未来应用"><a href="#2-未来应用" class="headerlink" title="2.未来应用"></a>2.未来应用</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706171619513.png" alt="image-20200706171619513"></p>
<h3 id="三：机器学习的定位"><a href="#三：机器学习的定位" class="headerlink" title="三：机器学习的定位"></a>三：机器学习的定位</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706172204133.png" alt="image-20200706172204133"></p>
<h4 id="不要孤立的看待机器学习，它和很多领域都有密切的联系"><a href="#不要孤立的看待机器学习，它和很多领域都有密切的联系" class="headerlink" title="不要孤立的看待机器学习，它和很多领域都有密切的联系"></a>不要孤立的看待机器学习，它和很多领域都有密切的联系</h4><h3 id="四：机器学习的框架"><a href="#四：机器学习的框架" class="headerlink" title="四：机器学习的框架"></a>四：机器学习的框架</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706172446522.png" alt="image-20200706172446522"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200706172809977.png" alt="image-20200706172809977"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>机器学习基础概念</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记3</title>
    <url>/2020/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/</url>
    <content><![CDATA[<h3 id="KNN-K近邻算法（K-Nearest-Neighbors）"><a href="#KNN-K近邻算法（K-Nearest-Neighbors）" class="headerlink" title="KNN -K近邻算法（K-Nearest Neighbors）"></a>KNN -K近邻算法（K-Nearest Neighbors）</h3><a id="more"></a>
<h4 id="一：KNN–非常适合初学者入门的算法"><a href="#一：KNN–非常适合初学者入门的算法" class="headerlink" title="一：KNN–非常适合初学者入门的算法"></a>一：KNN–非常适合初学者入门的算法</h4><ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707205845716.png" alt="image-20200707205845716"></li>
</ul>
<h5 id="1-什么是KNN"><a href="#1-什么是KNN" class="headerlink" title="1.什么是KNN"></a>1.什么是KNN</h5><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707210428247.png" alt="image-20200707210428247"></p>
</li>
<li><ul>
<li>上图解释：红色是良性肿瘤，蓝色是恶性肿瘤，绿色是一个新的不确定的肿瘤。这里设K=3（后面会讲如何取K值），表示选取离绿色最近的三个肿瘤，然后这3个之间进行投票（以自己的标签投票），最终蓝色：红色==3:0.因此我们有很大的概率认为绿色也是恶性肿瘤。</li>
<li>因此，KNN表示在K个样本中，哪个样本越多，就表示目标样本有很大概率是同一类别。</li>
</ul>
</li>
</ul>
<h5 id="2-KNN的特性"><a href="#2-KNN的特性" class="headerlink" title="2.KNN的特性"></a>2.KNN的特性</h5><ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707234150755.png" alt="image-20200707234150755"></li>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200707234227091.png" alt="image-20200707234227091"></li>
<li><ul>
<li>scikit_learn正是按这套流程进行的算法封装</li>
</ul>
</li>
</ul>
<h5 id="3-判断机器学习算法的性能"><a href="#3-判断机器学习算法的性能" class="headerlink" title="3.判断机器学习算法的性能"></a>3.判断机器学习算法的性能</h5><ul>
<li><p>考虑到真实环境下，将所有的原始数据都当成训练数据来训练模型是不恰当的，因此我们要进行训练和测试数据集切分(train test split)</p>
</li>
<li><ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200711013945748.png" alt="image-20200710224630969"></li>
</ul>
</li>
<li><p>注意：这里补充一下seed随机种子的直观理解：其实，设置seed（）里的数字就相当于设置了一个盛有随机数的“聚宝盆”，一个数字代表一个“聚宝盆”，当我们在seed（）的括号里设置相同的seed，“聚宝盆”就是一样的，那当然每次拿出的随机数就会相同（不要觉得就是从里面随机取数字，只要设置的seed相同取出地随机数就一样）。如果不设置seed，则每次会生成不同的随机数。（注：seed括号里的数值基本可以随便设置哦）<br>————————————————<br>版权声明：本文为CSDN博主「白糖炒栗子~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/weixin_41571493/article/details/80549833" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41571493/article/details/80549833</a></p>
<ul>
<li>np.random.seed(0)<br>np.random.rand(4,3)<br>Out[362]:<br>array([[0.5488135 , 0.71518937, 0.60276338],<pre><code>[0.54488318, 0.4236548 , 0.64589411],
[0.43758721, 0.891773  , 0.96366276],
[0.38344152, 0.79172504, 0.52889492]])</code></pre>np.random.seed(0)<br>np.random.rand(4,3)<br>Out[364]:<br>array([[0.5488135 , 0.71518937, 0.60276338],<pre><code>[0.54488318, 0.4236548 , 0.64589411],
[0.43758721, 0.891773  , 0.96366276],
[0.38344152, 0.79172504, 0.52889492]])</code></pre></li>
</ul>
</li>
<li><p>分类准确度：accuracy：详见jupyter</p>
</li>
<li><p>超参数</p>
<ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200710224630969.png" alt="image-20200711013945748"></p>
</li>
<li><p>如何寻找好的超参数</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200711014228711.png" alt="image-20200711014228711"></p>
<ul>
<li><p>KNN中其实除了K还有一个超参数，那就是距离的权重（它是距离的倒数）</p>
<ul>
<li><p>设红和蓝与绿色的距离分别为1,3,4</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200711021206076.png" alt="image-20200711021206076"></p>
<ul>
<li><p>若有三个类别，而k也等于3，那么就有可能出现平票的情况</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200711021519742.png" alt="image-20200711021519742"></p>
</li>
<li><p>补充：明可夫斯基距离</p>
<ul>
<li><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200711023118851.png" alt="image-20200711023118851"><ul>
<li>当p=1时是曼哈顿距离</li>
<li>当p=2时是欧拉距离</li>
<li>当p&gt;2时是其他距离</li>
</ul>
</li>
<li><h2 id="更多的距离定义（暂不做深入研究，只是了解）"><a href="#更多的距离定义（暂不做深入研究，只是了解）" class="headerlink" title="更多的距离定义（暂不做深入研究，只是了解）"></a>更多的距离定义（暂不做深入研究，只是了解）</h2></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200723233646364.png" alt="image-20200723233646364"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记7</title>
    <url>/2020/07/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07/</url>
    <content><![CDATA[<h3 id="回归算法的评价"><a href="#回归算法的评价" class="headerlink" title="回归算法的评价"></a>回归算法的评价</h3><a id="more"></a>

<h4 id="一、从简单线性回归引出横梁标准"><a href="#一、从简单线性回归引出横梁标准" class="headerlink" title="一、从简单线性回归引出横梁标准"></a>一、从简单线性回归引出横梁标准</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730220946800.png" alt="image-20200730220946800"></p>
<h5 id="衡量标准就是测试集中的真实值与测试集中的预测值的差的平方，但是该衡量标准与样本数量m有关。为了避免不同样本量的数据集带来的模型优劣争议，我们要将这个式子除以m，得到下图"><a href="#衡量标准就是测试集中的真实值与测试集中的预测值的差的平方，但是该衡量标准与样本数量m有关。为了避免不同样本量的数据集带来的模型优劣争议，我们要将这个式子除以m，得到下图" class="headerlink" title="衡量标准就是测试集中的真实值与测试集中的预测值的差的平方，但是该衡量标准与样本数量m有关。为了避免不同样本量的数据集带来的模型优劣争议，我们要将这个式子除以m，得到下图"></a>衡量标准就是测试集中的真实值与测试集中的预测值的差的平方，但是该衡量标准与样本数量m有关。为了避免不同样本量的数据集带来的模型优劣争议，我们要将这个式子除以m，得到下图</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730221356928.png" alt="image-20200730221356928"></p>
<h5 id="但是MSE会使得该数据集的量纲（单位）为原来的平方（比如米变成平方米），所以我们可以给MSE开根号使得它和原数据集的量纲相同，这就是RMSE"><a href="#但是MSE会使得该数据集的量纲（单位）为原来的平方（比如米变成平方米），所以我们可以给MSE开根号使得它和原数据集的量纲相同，这就是RMSE" class="headerlink" title="但是MSE会使得该数据集的量纲（单位）为原来的平方（比如米变成平方米），所以我们可以给MSE开根号使得它和原数据集的量纲相同，这就是RMSE"></a>但是MSE会使得该数据集的量纲（单位）为原来的平方（比如米变成平方米），所以我们可以给MSE开根号使得它和原数据集的量纲相同，这就是RMSE</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730221818237.png" alt="image-20200730221818237"></p>
<h5 id="同样我们还可以使用以下的评价算法，注意线性回归模型找最优参数时不能用绝对值（不是处处可导），但是评价时就可以用，它们是互不影响的。"><a href="#同样我们还可以使用以下的评价算法，注意线性回归模型找最优参数时不能用绝对值（不是处处可导），但是评价时就可以用，它们是互不影响的。" class="headerlink" title="同样我们还可以使用以下的评价算法，注意线性回归模型找最优参数时不能用绝对值（不是处处可导），但是评价时就可以用，它们是互不影响的。"></a>同样我们还可以使用以下的评价算法，注意线性回归模型找最优参数时不能用绝对值（不是处处可导），但是评价时就可以用，它们是互不影响的。</h5><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730222124641.png" alt="image-20200730222124641"></p>
<h3 id="二、RMSE-VS-MAE"><a href="#二、RMSE-VS-MAE" class="headerlink" title="二、RMSE VS  MAE"></a>二、RMSE VS  MAE</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730230527231.png" alt="image-20200730230527231"></p>
<h4 id="RMSE中的平方操作相当于放大了-max-y-true-y-predict-，所以开根号以后依然比MAE大，因此我们要想让RMSE或MSE更有意义，就要让差值尽量小。"><a href="#RMSE中的平方操作相当于放大了-max-y-true-y-predict-，所以开根号以后依然比MAE大，因此我们要想让RMSE或MSE更有意义，就要让差值尽量小。" class="headerlink" title="RMSE中的平方操作相当于放大了$$ max(y_{true}-y_{predict})$$，所以开根号以后依然比MAE大，因此我们要想让RMSE或MSE更有意义，就要让差值尽量小。"></a>RMSE中的平方操作相当于放大了$$ max(y_{true}-y_{predict})$$，所以开根号以后依然比MAE大，因此我们要想让RMSE或MSE更有意义，就要让差值尽量小。</h4><h3 id="三、最好的衡量线性回归法的指标"><a href="#三、最好的衡量线性回归法的指标" class="headerlink" title="三、最好的衡量线性回归法的指标"></a>三、最好的衡量线性回归法的指标</h3><h4 id="从分类算法的评价算法我们可以得出它可以通过0到1中的一个数来衡量模型的好坏。但由于RMSE和MSE只能得出平均差值，所以导致训练处理的模型不具有通用性（比如房价和学生成绩）"><a href="#从分类算法的评价算法我们可以得出它可以通过0到1中的一个数来衡量模型的好坏。但由于RMSE和MSE只能得出平均差值，所以导致训练处理的模型不具有通用性（比如房价和学生成绩）" class="headerlink" title="从分类算法的评价算法我们可以得出它可以通过0到1中的一个数来衡量模型的好坏。但由于RMSE和MSE只能得出平均差值，所以导致训练处理的模型不具有通用性（比如房价和学生成绩）"></a>从分类算法的评价算法我们可以得出它可以通过0到1中的一个数来衡量模型的好坏。但由于RMSE和MSE只能得出平均差值，所以导致训练处理的模型不具有通用性（比如房价和学生成绩）</h4><h4 id="因此，我们要使用以下算法来评价模型"><a href="#因此，我们要使用以下算法来评价模型" class="headerlink" title="因此，我们要使用以下算法来评价模型"></a>因此，我们要使用以下算法来评价模型</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730232425399.png" alt="image-20200730232425399"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730232723872.png" alt="image-20200730232723872"></p>
<h4 id="R2是衡量了我们模型没有产生错误的相应指标"><a href="#R2是衡量了我们模型没有产生错误的相应指标" class="headerlink" title="R2是衡量了我们模型没有产生错误的相应指标"></a>R2是衡量了我们模型没有产生错误的相应指标</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730233257406.png" alt="image-20200730233257406"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200730233453803.png" alt="image-20200730233453803"></p>
<h4 id="注意，Var指方差"><a href="#注意，Var指方差" class="headerlink" title="注意，Var指方差"></a>注意，Var指方差</h4>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>线性回归</tag>
        <tag>回归算法评价</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记6</title>
    <url>/2020/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06/</url>
    <content><![CDATA[<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><a id="more"></a>

<h4 id="一、线性回归简述"><a href="#一、线性回归简述" class="headerlink" title="一、线性回归简述"></a>一、线性回归简述</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726225427820.png" alt="image-20200726225427820"></p>
<ul>
<li><h5 id="什么是线性回归"><a href="#什么是线性回归" class="headerlink" title="什么是线性回归"></a>什么是线性回归</h5><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726225808532.png" alt="image-20200726225808532"></p>
</li>
<li><h5 id="注意：分类算法的横纵坐标都是样本特征；而回归算法的横纵坐标分别为样本特征和样本标签"><a href="#注意：分类算法的横纵坐标都是样本特征；而回归算法的横纵坐标分别为样本特征和样本标签" class="headerlink" title="注意：分类算法的横纵坐标都是样本特征；而回归算法的横纵坐标分别为样本特征和样本标签"></a>注意：分类算法的横纵坐标都是样本特征；而回归算法的横纵坐标分别为样本特征和样本标签</h5></li>
<li><h5 id="样本特征只有一个称为简单线性回归"><a href="#样本特征只有一个称为简单线性回归" class="headerlink" title="样本特征只有一个称为简单线性回归"></a>样本特征只有一个称为简单线性回归</h5></li>
</ul>
</li>
</ul>
<h3 id="二、简单线性回归"><a href="#二、简单线性回归" class="headerlink" title="二、简单线性回归"></a>二、简单线性回归</h3><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726230627487.png" alt="image-20200726230627487"></p>
</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726230701216.png" alt="image-20200726230701216"></p>
<h4 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h4><ul>
<li><h6 id="因为我们要考虑所有样本的差距，所以不能有正有负（可能会抵消为0），因此每个样本的差距值应该-gt-0。"><a href="#因为我们要考虑所有样本的差距，所以不能有正有负（可能会抵消为0），因此每个样本的差距值应该-gt-0。" class="headerlink" title="因为我们要考虑所有样本的差距，所以不能有正有负（可能会抵消为0），因此每个样本的差距值应该&gt;=0。"></a>因为我们要考虑所有样本的差距，所以不能有正有负（可能会抵消为0），因此每个样本的差距值应该&gt;=0。</h6></li>
<li><p>######由于我们希望真实值和预测值差距尽量小，所以需要求极值，而绝对值函数不是连续处处可导，所以我们改差值的平方函数。</p>
</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726231427640.png" alt="image-20200726231427640"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726231641441.png" alt="image-20200726231641441"></p>
<h4 id="说明：-1"><a href="#说明：-1" class="headerlink" title="说明："></a>说明：</h4><ul>
<li><p>损失函数：度量模型没有拟合到的样本的程度</p>
</li>
<li><p>效用函数：度量模型拟合到的样本的程度</p>
</li>
<li><p>近乎所有的参数学习算法都是这样来求解最优参数（线性回归，多项式回归，逻辑回归，SVM，神经网络等等）</p>
</li>
</ul>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726232703309.png" alt="image-20200726232703309"></p>
<p>####2.最小二乘法：</p>
<h5 id="推导过程（求解a和b）"><a href="#推导过程（求解a和b）" class="headerlink" title="推导过程（求解a和b）"></a>推导过程（求解a和b）</h5><p>首先求解参数b</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726234248085.png" alt="image-20200726234248085"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200726234339896.png" alt="image-20200726234339896"></p>
<p>然后求解参数a</p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200727000111783.png" alt="image-20200727000111783"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200727000132271.png" alt="image-20200727000132271"></p>
<h3 id="说明：其实到这里已经将参数a求了出来，但是为了编程实现方便，我们要进一步简化这个式子，请看下图，注意-bar-x和-bar-y-都是常数，所以可以提到求和符号前面"><a href="#说明：其实到这里已经将参数a求了出来，但是为了编程实现方便，我们要进一步简化这个式子，请看下图，注意-bar-x和-bar-y-都是常数，所以可以提到求和符号前面" class="headerlink" title="说明：其实到这里已经将参数a求了出来，但是为了编程实现方便，我们要进一步简化这个式子，请看下图，注意$ \bar x和\bar y $都是常数，所以可以提到求和符号前面"></a>说明：其实到这里已经将参数a求了出来，但是为了编程实现方便，我们要进一步简化这个式子，请看下图，注意$ \bar x和\bar y $都是常数，所以可以提到求和符号前面</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200727001049264.png" alt="image-20200727001049264"></p>
<h3 id="三，向量化运算"><a href="#三，向量化运算" class="headerlink" title="三，向量化运算"></a>三，向量化运算</h3><h4 id="在代码编写过程中使用for循环会使运行效率大大降低，所以我们要把循环去掉。"><a href="#在代码编写过程中使用for循环会使运行效率大大降低，所以我们要把循环去掉。" class="headerlink" title="在代码编写过程中使用for循环会使运行效率大大降低，所以我们要把循环去掉。"></a>在代码编写过程中使用for循环会使运行效率大大降低，所以我们要把循环去掉。</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200729233852136.png" alt="image-20200729233852136"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200729233924794.png" alt="image-20200729233924794"></p>
<h4 id="所以分子为-vec-vec-x-bar-x-cdot-vec-vec-y-bar-y"><a href="#所以分子为-vec-vec-x-bar-x-cdot-vec-vec-y-bar-y" class="headerlink" title="所以分子为$$ (\vec{\vec{x}-\bar x})\cdot(\vec{\vec{y}-\bar y} )$$"></a>所以分子为$$ (\vec{\vec{x}-\bar x})\cdot(\vec{\vec{y}-\bar y} )$$</h4><h4 id="分母为-vec-vec-x-bar-x-cdot-vec-vec-x-bar-x"><a href="#分母为-vec-vec-x-bar-x-cdot-vec-vec-x-bar-x" class="headerlink" title="分母为$$ (\vec{\vec{x}-\bar x})\cdot(\vec{\vec{x}-\bar x}) $$"></a>分母为$$ (\vec{\vec{x}-\bar x})\cdot(\vec{\vec{x}-\bar x}) $$</h4><h4 id="注意，这种思想非常重要，请以后常用"><a href="#注意，这种思想非常重要，请以后常用" class="headerlink" title="注意，这种思想非常重要，请以后常用"></a>注意，这种思想非常重要，请以后常用</h4>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>线性回归</tag>
        <tag>简单线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记5</title>
    <url>/2020/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05/</url>
    <content><![CDATA[<h3 id="更多有关KNN的思考"><a href="#更多有关KNN的思考" class="headerlink" title="更多有关KNN的思考"></a>更多有关KNN的思考</h3><a id="more"></a>

<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724025657646.png" alt="image-20200724025657646"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724025727331.png" alt="image-20200724025727331"></p>
<h4 id="解释：可以把离绿球最近的三个蓝球的均值作为绿球的值，也可以将距离权重考虑进去求加权平均数。总之，这些都是回归问题。（sklearn其实已经封装好了KNN解决回归问题的库：KNeighborsRegressor）"><a href="#解释：可以把离绿球最近的三个蓝球的均值作为绿球的值，也可以将距离权重考虑进去求加权平均数。总之，这些都是回归问题。（sklearn其实已经封装好了KNN解决回归问题的库：KNeighborsRegressor）" class="headerlink" title="解释：可以把离绿球最近的三个蓝球的均值作为绿球的值，也可以将距离权重考虑进去求加权平均数。总之，这些都是回归问题。（sklearn其实已经封装好了KNN解决回归问题的库：KNeighborsRegressor）"></a>解释：可以把离绿球最近的三个蓝球的均值作为绿球的值，也可以将距离权重考虑进去求加权平均数。总之，这些都是回归问题。（sklearn其实已经封装好了KNN解决回归问题的库：KNeighborsRegressor）</h4><h3 id="它的缺点"><a href="#它的缺点" class="headerlink" title="它的缺点"></a>它的缺点</h3><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724030254962.png" alt="image-20200724030254962"></p>
</li>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724030519829.png" alt="image-20200724030519829"></p>
<ul>
<li><h4 id="解释：缺点2：拿上图红蓝绿球来举例，假如k-3，而其中两个是红色，一个是蓝色。按照KNN就会认定绿球为红色类，但事实上绿球的标签是蓝色类"><a href="#解释：缺点2：拿上图红蓝绿球来举例，假如k-3，而其中两个是红色，一个是蓝色。按照KNN就会认定绿球为红色类，但事实上绿球的标签是蓝色类" class="headerlink" title="解释：缺点2：拿上图红蓝绿球来举例，假如k=3，而其中两个是红色，一个是蓝色。按照KNN就会认定绿球为红色类，但事实上绿球的标签是蓝色类"></a>解释：缺点2：拿上图红蓝绿球来举例，假如k=3，而其中两个是红色，一个是蓝色。按照KNN就会认定绿球为红色类，但事实上绿球的标签是蓝色类</h4></li>
</ul>
</li>
<li><h4 id="缺点4："><a href="#缺点4：" class="headerlink" title="缺点4："></a>缺点4：<img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724031158354.png" alt="image-20200724031158354"></h4></li>
</ul>
<h3 id="机器学习流程回顾"><a href="#机器学习流程回顾" class="headerlink" title="机器学习流程回顾"></a>机器学习流程回顾</h3><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724031341729.png" alt="image-20200724031341729"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习笔记4</title>
    <url>/2020/07/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04/</url>
    <content><![CDATA[<h3 id="数据归一化与标准化"><a href="#数据归一化与标准化" class="headerlink" title="数据归一化与标准化"></a>数据归一化与标准化</h3><a id="more"></a>

<h4 id="一，为什么要进行数据归一化或归一化"><a href="#一，为什么要进行数据归一化或归一化" class="headerlink" title="一，为什么要进行数据归一化或归一化"></a>一，为什么要进行数据归一化或归一化</h4><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200723234524737.png" alt="image-20200723234524737"></p>
<p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200723234716174.png" alt="image-20200723234716174"></p>
<ul>
<li><h4 id="这张图表示样本之间的距离又会被肿瘤大小来主导"><a href="#这张图表示样本之间的距离又会被肿瘤大小来主导" class="headerlink" title="这张图表示样本之间的距离又会被肿瘤大小来主导"></a>这张图表示样本之间的距离又会被肿瘤大小来主导</h4></li>
<li><p>####因此我们需要统一进行数据归一化</p>
</li>
</ul>
<h3 id="二，什么是数据归一化或标准化"><a href="#二，什么是数据归一化或标准化" class="headerlink" title="二，什么是数据归一化或标准化"></a>二，什么是数据归一化或标准化</h3><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200723235207881.png" alt="image-20200723235207881"></p>
</li>
<li><h4 id="最值归一化（normalization）适用于分布有明显边界的情况。比如像工资就不能用最值归一化（工资无上限）"><a href="#最值归一化（normalization）适用于分布有明显边界的情况。比如像工资就不能用最值归一化（工资无上限）" class="headerlink" title="最值归一化（normalization）适用于分布有明显边界的情况。比如像工资就不能用最值归一化（工资无上限）"></a>最值归一化（normalization）适用于分布有明显边界的情况。比如像工资就不能用最值归一化（工资无上限）</h4></li>
</ul>
<h4 id="第二种是标准化"><a href="#第二种是标准化" class="headerlink" title="第二种是标准化"></a>第二种是标准化</h4><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724000028651.png" alt="image-20200724000028651"></p>
</li>
<li><h5 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h5><ul>
<li><h4 id="此处老师讲错，应该为标准化，而不是均值方差归一化"><a href="#此处老师讲错，应该为标准化，而不是均值方差归一化" class="headerlink" title="此处老师讲错，应该为标准化，而不是均值方差归一化"></a>此处老师讲错，应该为标准化，而不是均值方差归一化</h4></li>
<li><h4 id="s表示标准差。除非数据集有明确的边界，（初学情况）一般情况下都使用标准化"><a href="#s表示标准差。除非数据集有明确的边界，（初学情况）一般情况下都使用标准化" class="headerlink" title="s表示标准差。除非数据集有明确的边界，（初学情况）一般情况下都使用标准化"></a>s表示标准差。除非数据集有明确的边界，（初学情况）一般情况下都使用标准化</h4></li>
<li><h4 id="其实就是利用标准化处理将正态分布转为了标准正态分布"><a href="#其实就是利用标准化处理将正态分布转为了标准正态分布" class="headerlink" title="其实就是利用标准化处理将正态分布转为了标准正态分布"></a>其实就是利用标准化处理将正态分布转为了标准正态分布</h4></li>
<li><h4 id="深入了解请看https-www-jiqizhixin-com-articles-19070701-https-www-zhihu-com-question-56891433"><a href="#深入了解请看https-www-jiqizhixin-com-articles-19070701-https-www-zhihu-com-question-56891433" class="headerlink" title="深入了解请看https://www.jiqizhixin.com/articles/19070701 https://www.zhihu.com/question/56891433"></a>深入了解请看<a href="https://www.jiqizhixin.com/articles/19070701" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/19070701</a> <a href="https://www.zhihu.com/question/56891433" target="_blank" rel="noopener">https://www.zhihu.com/question/56891433</a></h4></li>
<li><h4 id="在线演示标准正态分布https-www-shuxuele-com-data-standard-normal-distribution-table-html"><a href="#在线演示标准正态分布https-www-shuxuele-com-data-standard-normal-distribution-table-html" class="headerlink" title="在线演示标准正态分布https://www.shuxuele.com/data/standard-normal-distribution-table.html"></a>在线演示标准正态分布<a href="https://www.shuxuele.com/data/standard-normal-distribution-table.html" target="_blank" rel="noopener">https://www.shuxuele.com/data/standard-normal-distribution-table.html</a></h4></li>
</ul>
</li>
</ul>
<h3 id="三，这两种的区别"><a href="#三，这两种的区别" class="headerlink" title="三，这两种的区别"></a>三，这两种的区别</h3><h5 id="最值归一化"><a href="#最值归一化" class="headerlink" title="最值归一化"></a>最值归一化</h5><ul>
<li>数据集必须得有边界，否则会出现偏差很悬殊的值</li>
</ul>
<h5 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h5><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724020154141.png" alt="image-20200724020154141"></p>
</li>
<li><h5 id="平均值是曲线的中心。这是曲线的最高点，因为大多数点都在平均值附近；"><a href="#平均值是曲线的中心。这是曲线的最高点，因为大多数点都在平均值附近；" class="headerlink" title="平均值是曲线的中心。这是曲线的最高点，因为大多数点都在平均值附近；"></a>平均值是曲线的中心。这是曲线的最高点，因为大多数点都在平均值附近；</h5></li>
<li><h5 id="标准化更符合统计学假设（自然界大多数符合正态分布）：对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。"><a href="#标准化更符合统计学假设（自然界大多数符合正态分布）：对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。" class="headerlink" title="标准化更符合统计学假设（自然界大多数符合正态分布）：对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。"></a>标准化更符合统计学假设（自然界大多数符合正态分布）：对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。</h5></li>
<li><h5 id="新的数据由于对方差进行了归一化，这时候每个维度的量纲其实已经等价了，每个维度都服从均值为0、方差1的正态分布，在计算距离的时候，每个维度都是去量纲化的，避免了不同量纲的选取对距离计算产生的巨大影响。"><a href="#新的数据由于对方差进行了归一化，这时候每个维度的量纲其实已经等价了，每个维度都服从均值为0、方差1的正态分布，在计算距离的时候，每个维度都是去量纲化的，避免了不同量纲的选取对距离计算产生的巨大影响。" class="headerlink" title="新的数据由于对方差进行了归一化，这时候每个维度的量纲其实已经等价了，每个维度都服从均值为0、方差1的正态分布，在计算距离的时候，每个维度都是去量纲化的，避免了不同量纲的选取对距离计算产生的巨大影响。"></a>新的数据由于对方差进行了归一化，这时候每个维度的量纲其实已经等价了，每个维度都服从均值为0、方差1的正态分布，在计算距离的时候，每个维度都是去量纲化的，避免了不同量纲的选取对距离计算产生的巨大影响。</h5></li>
</ul>
<h3 id="四，对测试数据集如何归一化或标准化"><a href="#四，对测试数据集如何归一化或标准化" class="headerlink" title="四，对测试数据集如何归一化或标准化"></a>四，对测试数据集如何归一化或标准化</h3><ul>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724022251989.png" alt="image-20200724022251989"></p>
</li>
<li><p>####结论：因为一个模型是要投入生产生活中的，所以我们要让测试数据集也要使用训练数据集的均值和标准差</p>
</li>
<li><p><img src="https://gitee.com/macljc/myimg/raw/master/imgs/image-20200724022712834.png" alt="image-20200724022712834"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>数据预处理</tag>
      </tags>
  </entry>
</search>
